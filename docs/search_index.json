[
["moderation-analysis.html", "Topic 10 Moderation analysis 10.1 Overview 10.2 What is moderation? 10.3 What packages do we need? 10.4 What is moderation? 10.5 Moderation: step-by-step", " Topic 10 Moderation analysis Additional moderation example: 10.1 Overview What is moderation? Moderation analysis in more detail Grand Mean Centering Checking Assumptions Interpreting Moderation Bootstrapping Moderation 10.2 What is moderation? There is a direct relationship between X and Y but it is affected by a moderator (M) In the above model, we theorise that Time in counselling predicts General Wellbeing but the strength of the relationship is affected by the level of Rapport with counsellor 10.3 What packages do we need? gvlma (for checking assumptions) interactions (for generating interaction plot) Rockchalk (for testing simple slopes) car (includes a Boot() function to bootstrap regression models ) 10.4 What is moderation? The relationship between a predictor (X) and outcome (Y) is affected by another variable (M) This is referred to as an interaction (similar to interaction in standard regression) A moderator can effect the direction and/or strength of a relationship between X and Y Here we might find that the relationship between Time in counselling and General Wellbeing is strong for those who have a strong rapport with their counselling psychologist and weak for those who do not have good rapport with their counselling psychologist. Very similar to multiple regression lm(Y ~ X + M + X*M) Moderation analysis includes X, Z and the interaction between X and Z If we find a moderation effect it becomes the focus of our analysis (the independent role of X and Z becomes less important) In the plot above: The blue line is the “standard” regression line The black line is when the moderator is “low” (-1sd) The dotted line is when the moderator is “high” (+1sd) 10.5 Moderation: step-by-step 10.5.1 Step 1: Grand Mean Centering Regression coefficients (b values) are based on predicting Y when X = 0 Not all measures actually have a zero value To make results easier to interpret, we can centre our data around the grand mean of the data (making the mean 0) The mean of the full sample is subtracted from the value This is similar to z-score (i.e. a standardised score) To do this in R, we can use the scale() function: Xc &lt;- scale(X, center=TRUE, scale=FALSE) #Centering X; Mc &lt;- scale(M, center=TRUE, scale=FALSE) #Centering M; We then use the centred data in our analysis We can see that the difference between the original data is the mean of the data. Xc &lt;- scale(X, center=TRUE, scale=FALSE) #Centering X; X ## [1] 171.0767 173.3888 185.9110 175.4936 175.9050 187.0055 178.2264 166.1446 170.1920 ## [10] 171.8804 183.5686 177.5187 177.8054 175.7748 171.1091 187.5084 178.4850 161.2337 ## [19] 179.9095 171.6905 167.5252 173.4742 167.8180 169.8978 170.6247 163.1931 180.8645 ## [28] 176.0736 167.0330 183.7767 177.9852 172.9345 181.2659 181.1469 180.7511 179.8205 ## [37] 178.8774 174.5666 172.8583 172.3367 170.1371 173.5446 166.1422 190.1827 183.4557 ## [46] 167.1382 172.1798 171.7334 180.4598 174.4164 176.7732 174.8002 174.6999 184.5802 ## [55] 173.4196 185.6153 164.1587 179.0923 175.8670 176.5116 177.6575 171.4837 172.6675 ## [64] 167.8700 167.4975 177.1247 178.1375 175.3710 181.4559 189.3506 171.5628 158.8358 ## [73] 182.0402 170.0356 170.1839 182.1790 173.0066 166.4550 176.2691 174.0278 175.0403 ## [82] 177.6970 172.4054 179.5106 173.4566 177.3225 182.6779 178.0463 172.7185 183.0417 ## [91] 181.9545 178.8388 176.6711 170.6047 184.5246 170.7982 190.3113 185.7283 173.3501 ## [100] 167.8151 head(Xc) ## [,1] ## [1,] -4.5561709 ## [2,] -2.2440838 ## [3,] 10.2781168 ## [4,] -0.1392826 ## [5,] 0.2721728 ## [6,] 11.3726135 mean(X) ## [1] 175.6328 X[1]-Xc[1] ## [1] 175.6328 #Centering Data Moddata$timeInCounselling_centred &lt;- c(scale(timeInCounselling, center=TRUE, scale=FALSE)) #Centering IV; Moddata$rapportLevel_centred &lt;- c(scale(rapportLevel, center=TRUE, scale=FALSE)) #Centering moderator; #Moderation &quot;By Hand&quot; with centred data library(gvlma) fitMod &lt;- lm(generalWellbeing ~ timeInCounselling_centred *rapportLevel_centred , data = Moddata) #Model interacts IV &amp; moderator library(interactions) ip &lt;- interact_plot(fitMod, pred = timeInCounselling_centred, modx = rapportLevel_centred) ip 10.5.1.1 Do I need to mean centre my data? It is worth noting: It does not change the results of your interaction (coefficient, standard error or significance tests). It will change the results of the direct effects (the individual predictors in your model). It is a step that tries to ensure that the coefficients of the predictor and moderator are meaningful in relation to each other. In some cases, it might not be necessary to mean centre at all. However, there is no harm in doing so, and it could potentially be helpful. Hayes (2013) discusses mean centering, pp. 282-290. McClelland, G. H., Irwin, J. R., Disatnik, D., &amp; Sivan, L. (2017). Multicollinearity is a red herring in the search for moderator variables: A guide to interpreting moderated multiple regression models and a critique of Iacobucci, Schneider, Popovich, and Bakamitsos (2016). Behavior research methods, 49(1), 394-402. 10.5.2 Step 2: Check assumptions We can use the gvlma function to check regression assumptions library(gvlma) gvlma(fitMod) ## ## Call: ## lm(formula = generalWellbeing ~ timeInCounselling_centred * rapportLevel_centred, ## data = Moddata) ## ## Coefficients: ## (Intercept) ## 21.1851 ## timeInCounselling_centred ## 0.8971 ## rapportLevel_centred ## 0.5842 ## timeInCounselling_centred:rapportLevel_centred ## 0.1495 ## ## ## ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS ## USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM: ## Level of Significance = 0.05 ## ## Call: ## gvlma(x = fitMod) ## ## Value p-value Decision ## Global Stat 9.6949 0.04589 Assumptions NOT satisfied! ## Skewness 7.7571 0.00535 Assumptions NOT satisfied! ## Kurtosis 1.2182 0.26972 Assumptions acceptable. ## Link Function 0.5287 0.46716 Assumptions acceptable. ## Heteroscedasticity 0.1910 0.66207 Assumptions acceptable. The “global stat” is an attempt to check multiple assumptions of linear model: Pena, E. A., &amp; Slate, E. H. (2006). Global validation of linear model assumptions. Journal of the American Statistical Association, 101(473), 341-354. Since one of the underlying assumptions is violated, the overall stat is also not acceptable. The data looks skewed, we should transform it or perhaps use bootstrapping 10.5.3 Step 3: Moderation Analysis fitMod &lt;- lm(generalWellbeing ~ timeInCounselling_centred *rapportLevel_centred , data = Moddata) #Model interacts IV &amp; moderator #Model interacts IV &amp; moderator summary(fitMod) ## ## Call: ## lm(formula = generalWellbeing ~ timeInCounselling_centred * rapportLevel_centred, ## data = Moddata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.121 -8.938 -0.670 5.840 37.396 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 21.18508 1.14115 18.565 &lt; 2e-16 ## timeInCounselling_centred 0.89707 0.33927 2.644 0.009569 ## rapportLevel_centred 0.58416 0.15117 3.864 0.000203 ## timeInCounselling_centred:rapportLevel_centred 0.14948 0.04022 3.716 0.000340 ## ## (Intercept) *** ## timeInCounselling_centred ** ## rapportLevel_centred *** ## timeInCounselling_centred:rapportLevel_centred *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.33 on 96 degrees of freedom ## Multiple R-squared: 0.2737,\tAdjusted R-squared: 0.251 ## F-statistic: 12.06 on 3 and 96 DF, p-value: 9.12e-07 The results above show that there is a moderated effect 10.5.3.1 Visualising the moderation effect We use an approach called simple slopes to visualise the moderation effect interact_plot(fitMod, pred = timeInCounselling_centred, modx = rapportLevel_centred) The rockchalk package includes useful functions for visualising simple slopes library(rockchalk) fitMod &lt;- lm(generalWellbeing ~ timeInCounselling *rapportLevel , data = Moddata) summary(fitMod) ## ## Call: ## lm(formula = generalWellbeing ~ timeInCounselling * rapportLevel, ## data = Moddata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.121 -8.938 -0.670 5.840 37.396 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 17.28006 3.17944 5.435 4.15e-07 *** ## timeInCounselling 0.15510 0.42033 0.369 0.71296 ## rapportLevel -0.38484 0.29916 -1.286 0.20140 ## timeInCounselling:rapportLevel 0.14948 0.04022 3.716 0.00034 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.33 on 96 degrees of freedom ## Multiple R-squared: 0.2737,\tAdjusted R-squared: 0.251 ## F-statistic: 12.06 on 3 and 96 DF, p-value: 9.12e-07 slopes &lt;- plotSlopes(fitMod, modx = &quot;rapportLevel&quot;, plotx = &quot;timeInCounselling&quot;) testSlopes &lt;- testSlopes(slopes) ## Values of rapportLevel OUTSIDE this interval: ## lo hi ## -11.580166 3.634439 ## cause the slope of (b1 + b2*rapportLevel)timeInCounselling to be statistically significant plot(testSlopes) 10.5.4 Step 4: Bootstrapping The car package includes a function to bootstrap regression library(car) bootstrapModel &lt;- Boot(fitMod, R=999) confint(fitMod) ## 2.5 % 97.5 % ## (Intercept) 10.96891826 23.5912086 ## timeInCounselling -0.67926290 0.9894532 ## rapportLevel -0.97866229 0.2089882 ## timeInCounselling:rapportLevel 0.06963667 0.2293205 confint(bootstrapModel) ## Bootstrap bca confidence intervals ## ## 2.5 % 97.5 % ## (Intercept) 11.57230420 23.7222700 ## timeInCounselling -0.61780918 1.0397199 ## rapportLevel -0.90786799 0.2558502 ## timeInCounselling:rapportLevel 0.05806412 0.2146814 summary(bootstrapModel) ## ## Number of bootstrap replications R = 999 ## original bootBias bootSE bootMed ## (Intercept) 17.28006 -0.13667103 3.165301 17.05431 ## timeInCounselling 0.15510 0.01637117 0.399550 0.15929 ## rapportLevel -0.38484 0.00716631 0.294061 -0.38218 ## timeInCounselling:rapportLevel 0.14948 -0.00052838 0.038516 0.14974 hist(bootstrapModel) "]
]
